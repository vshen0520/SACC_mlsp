{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74805e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wave\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from python_speech_features import fbank\n",
    "from audio2numpy import open_audio\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cb8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "data=pd.read_csv(\"/Users/anqiliu/Desktop/SACC/archive/speakers_all.csv\",index_col='speakerid')\n",
    "data = data.iloc[:,:8]\n",
    "data = data[data['file_missing?']==False]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '/Users/anqiliu/Desktop/SACC/archive/recordings/recordings'\n",
    "OUTPUT_DIR = 'results'\n",
    "parent_list = os.listdir(INPUT_DIR)\n",
    "print(len(parent_list))\n",
    "\n",
    "print(set(data['filename']+'.mp3') - set(parent_list)) # find contries whose recordings are misssing\n",
    "\n",
    "data = data.drop(data[data['filename']=='sinhalese1'].index)\n",
    "data = data.drop(data[data['filename']=='nicaragua'].index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 classification\n",
    "English = data[data['native_language']=='english']\n",
    "French = data[data['native_language']=='french']\n",
    "Spanish= data[data['native_language']=='spanish']\n",
    "Arabic = data[data['native_language']=='arabic']\n",
    "dataSub = English.append(French).append(Spanish).append(Arabic)\n",
    "dataSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3db8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(INPUT_DIR):  \n",
    "    parent_list = dataSub['filename']+ '.mp3'\n",
    "    # 2138 recordings each has 20 862-dimension MFCCs (dim depends on duration)\n",
    "    mfcc_feat = np.zeros((len(parent_list),20,862))\n",
    "    i=0  \n",
    "    for file in parent_list[:]:\n",
    "        f_name = str(INPUT_DIR+file)\n",
    "        y, sr = librosa.load(f_name,duration = 20)    # duration 20s, SAMPLE_RATE = 22050 default\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr) \n",
    " \n",
    "        if len(mfcc[1]) < 862:\n",
    "            offset = 862 - len(mfcc[1]) # padding starting point\n",
    "            mfcc= np.pad(mfcc,((0,0),(offset,0)), 'constant')\n",
    "\n",
    "        mfcc_feat[i,:,:]=mfcc\n",
    "        i+=1\n",
    "        \n",
    "    return mfcc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ead43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbank(INPUT_DIR):\n",
    "    parent_list = dataSub['filename']+ '.mp3'\n",
    "    # 2138 recordings each has 20 3990-dimension Fbanks (dim depends on duration)\n",
    "    fbank_feat = np.zeros((len(parent_list),20,3990))\n",
    "    i=0  \n",
    "    for file in parent_list[:]:\n",
    "        f_name = str(INPUT_DIR+file)\n",
    "        y, sr = librosa.load(f_name,sr=None,duration=20)   # duration 20s, uses the native sampling rate\n",
    "        fb = fbank(y,sr/2,nfft=1103,nfilt=20)[0].T\n",
    "        \n",
    "        if len(fb[1]) < 3990:\n",
    "            offset = 3990 - len(fb[1]) # padding starting point\n",
    "            fb= np.pad(fb,((0,0),(offset,0)), 'constant')\n",
    "   \n",
    "        if len(fb[1]) > 3990:\n",
    "            fb = fb[:,:3990]    # extract the first 3990 dims\n",
    "        \n",
    "        fbank_feat[i,:,:]= fb\n",
    "        i+=1\n",
    "        \n",
    "    return fbank_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '/Users/anqiliu/Desktop/SACC/archive/recordings/recordings'\n",
    "mfcc_feat = get_mfcc(INPUT_DIR)\n",
    "np.save(\"/Users/anqiliu/Desktop/SACC/Results/mfcc_feat4.npy\",mfcc_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30796143",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbank_feat = get_fbank(INPUT_DIR)\n",
    "np.save(\"/Users/anqiliu/Desktop/SACC/Results/fbank_feat4.npy\",fbank_feat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
